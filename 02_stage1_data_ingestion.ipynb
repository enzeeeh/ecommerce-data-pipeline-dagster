{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f67305e",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Stage 1: Data Ingestion Pipeline\n",
    "## Amazon Sales Data ‚Üí DuckDB Processing\n",
    "\n",
    "**Objective**: Streamlined data ingestion process with integrated data cleaning and DuckDB storage\n",
    "\n",
    "**Key Features**:\n",
    "- ‚úÖ Production-ready data cleaning pipeline\n",
    "- ‚úÖ DuckDB integration for analytical storage\n",
    "- ‚úÖ Automated quality validation\n",
    "- ‚úÖ Business logic for missing values\n",
    "\n",
    "**Pipeline Steps**:\n",
    "1. Environment Setup & Configuration\n",
    "2. Data Loading with Cleaning\n",
    "3. DuckDB Schema Creation\n",
    "4. Data Ingestion & Validation\n",
    "5. Quality Assurance Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1b85d",
   "metadata": {},
   "source": [
    "## üì¶ Step 1.1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ac562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Required libraries imported successfully\n",
      "üìä Pandas version: 2.3.3\n",
      "ü¶Ü DuckDB version: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Utility libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Required libraries imported successfully\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"ü¶Ü DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05067eba",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 1.2: Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd7eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Source file found: Amazon Sale Report.csv\n",
      "üìÅ File size: 65.7 MB\n",
      "‚öôÔ∏è Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion Configuration (Based on exploration findings)\n",
    "CONFIG = {\n",
    "    # File paths\n",
    "    'csv_file': 'Amazon Sale Report.csv',\n",
    "    'duckdb_file': 'amazon_sales.duckdb',\n",
    "    \n",
    "    # Key business columns (identified from exploration)\n",
    "    'business_columns': {\n",
    "        'date_col': 'Date',\n",
    "        'amount_col': 'Amount', \n",
    "        'category_col': 'Category',\n",
    "        'status_col': 'Status',\n",
    "        'courier_status_col': 'Courier Status',\n",
    "        'currency_col': 'currency'\n",
    "    },\n",
    "    \n",
    "    # Data cleaning rules (from exploration insights)\n",
    "    'cleaning_rules': {\n",
    "        'default_currency': 'INR',\n",
    "        'cancelled_amount_value': 0.0,\n",
    "        'date_format': '%m-%d-%y'\n",
    "    },\n",
    "    \n",
    "    # DuckDB table names\n",
    "    'tables': {\n",
    "        'raw_data': 'amazon_sales_raw',\n",
    "        'monthly_revenue': 'monthly_revenue_by_category',\n",
    "        'daily_orders': 'daily_orders_by_status'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Verify file exists\n",
    "csv_path = Path(CONFIG['csv_file'])\n",
    "if csv_path.exists():\n",
    "    file_size_mb = csv_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"‚úÖ Source file found: {CONFIG['csv_file']}\")\n",
    "    print(f\"üìÅ File size: {file_size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Source file not found: {CONFIG['csv_file']}\")\n",
    "    \n",
    "print(\"‚öôÔ∏è Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b25410",
   "metadata": {},
   "source": [
    "## üßπ Step 1.3: Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa5b85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Data cleaning function defined successfully\n"
     ]
    }
   ],
   "source": [
    "def clean_amazon_sales_data(df, config):\n",
    "    \"\"\"\n",
    "    Production-ready data cleaning function based on exploration insights\n",
    "    \n",
    "    Business Rules:\n",
    "    - Cancelled orders with missing Amount ‚Üí Set Amount = 0\n",
    "    - Missing currency ‚Üí Set to 'INR' (default)\n",
    "    - Flag data quality issues for non-cancelled orders with missing Amount\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    cleaning_stats = {}\n",
    "    \n",
    "    print(\"üßπ Applying data cleaning pipeline...\")\n",
    "    \n",
    "    # Rule 1: Handle missing Amount values\n",
    "    amount_col = config['business_columns']['amount_col']\n",
    "    status_col = config['business_columns']['status_col']\n",
    "    currency_col = config['business_columns']['currency_col']\n",
    "    \n",
    "    # Count original missing values\n",
    "    original_amount_nulls = df_clean[amount_col].isna().sum()\n",
    "    original_currency_nulls = df_clean[currency_col].isna().sum()\n",
    "    \n",
    "    # Set Amount = 0 for cancelled orders with missing Amount\n",
    "    cancelled_missing_amount = (df_clean[status_col] == 'Cancelled') & (df_clean[amount_col].isna())\n",
    "    cancelled_count = cancelled_missing_amount.sum()\n",
    "    df_clean.loc[cancelled_missing_amount, amount_col] = config['cleaning_rules']['cancelled_amount_value']\n",
    "    \n",
    "    # Flag non-cancelled orders with missing Amount (data quality issue)\n",
    "    non_cancelled_missing = (df_clean[status_col] != 'Cancelled') & (df_clean[amount_col].isna())\n",
    "    flagged_count = non_cancelled_missing.sum()\n",
    "    if flagged_count > 0:\n",
    "        df_clean.loc[non_cancelled_missing, 'data_quality_flag'] = 'missing_amount_non_cancelled'\n",
    "    \n",
    "    # Rule 2: Set default currency for missing values\n",
    "    currency_missing = df_clean[currency_col].isna()\n",
    "    currency_count = currency_missing.sum()\n",
    "    df_clean.loc[currency_missing, currency_col] = config['cleaning_rules']['default_currency']\n",
    "    \n",
    "    # Rule 3: Convert date column to proper datetime format\n",
    "    date_col = config['business_columns']['date_col']\n",
    "    df_clean[date_col] = pd.to_datetime(df_clean[date_col], format=config['cleaning_rules']['date_format'])\n",
    "    \n",
    "    # Cleaning statistics\n",
    "    cleaning_stats = {\n",
    "        'original_amount_nulls': original_amount_nulls,\n",
    "        'cancelled_orders_fixed': cancelled_count,\n",
    "        'non_cancelled_flagged': flagged_count,\n",
    "        'currency_defaults_set': currency_count,\n",
    "        'final_amount_nulls': df_clean[amount_col].isna().sum(),\n",
    "        'final_currency_nulls': df_clean[currency_col].isna().sum()\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Cleaned {cancelled_count} cancelled orders (Amount ‚Üí 0)\")\n",
    "    print(f\"‚úÖ Set default currency for {currency_count} records\")\n",
    "    print(f\"‚ö†Ô∏è  Flagged {flagged_count} non-cancelled orders with missing Amount\")\n",
    "    print(f\"üìä Final Amount nulls: {cleaning_stats['final_amount_nulls']}\")\n",
    "    \n",
    "    return df_clean, cleaning_stats\n",
    "\n",
    "print(\"üîß Data cleaning function defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fbf72",
   "metadata": {},
   "source": [
    "## ü¶Ü Step 1.4: DuckDB Connection & Schema Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720d0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DuckDB connection established: amazon_sales.duckdb\n",
      "‚úÖ Created table: amazon_sales_raw\n",
      "‚úÖ Created table: monthly_revenue_by_category\n",
      "‚úÖ Created table: daily_orders_by_status\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB and create schema\n",
    "def create_duckdb_schema(config):\n",
    "    \"\"\"Create DuckDB connection and define schemas for all tables\"\"\"\n",
    "    \n",
    "    conn = duckdb.connect(config['duckdb_file'])\n",
    "    \n",
    "    # Raw data table schema (optimized for Amazon sales data)\n",
    "    raw_table_ddl = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {config['tables']['raw_data']} (\n",
    "        -- Identifiers\n",
    "        index_id INTEGER,\n",
    "        order_id VARCHAR,\n",
    "        \n",
    "        -- Date and Time\n",
    "        date_col DATE,\n",
    "        \n",
    "        -- Product Information  \n",
    "        category VARCHAR,\n",
    "        size VARCHAR,\n",
    "        sku VARCHAR,\n",
    "        asin VARCHAR,\n",
    "        style VARCHAR,\n",
    "        \n",
    "        -- Order Details\n",
    "        status VARCHAR,\n",
    "        courier_status VARCHAR,\n",
    "        qty INTEGER,\n",
    "        amount DECIMAL(10,2),\n",
    "        currency VARCHAR(10),\n",
    "        \n",
    "        -- Customer Information\n",
    "        ship_service_level VARCHAR,\n",
    "        ship_city VARCHAR,\n",
    "        ship_state VARCHAR,\n",
    "        ship_postal_code INTEGER,\n",
    "        ship_country VARCHAR,\n",
    "        \n",
    "        -- Sales Channel\n",
    "        sales_channel VARCHAR,\n",
    "        fulfilled_by VARCHAR,\n",
    "        promotion_ids VARCHAR,\n",
    "        \n",
    "        -- Data Quality\n",
    "        data_quality_flag VARCHAR,\n",
    "        \n",
    "        -- Metadata\n",
    "        ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # Monthly revenue by category analytical table\n",
    "    monthly_revenue_ddl = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {config['tables']['monthly_revenue']} (\n",
    "        year_month VARCHAR,\n",
    "        category VARCHAR,\n",
    "        total_revenue DECIMAL(12,2),\n",
    "        order_count INTEGER,\n",
    "        avg_order_value DECIMAL(10,2),\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # Daily orders by status analytical table  \n",
    "    daily_orders_ddl = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {config['tables']['daily_orders']} (\n",
    "        order_date DATE,\n",
    "        status VARCHAR,\n",
    "        order_count INTEGER,\n",
    "        total_quantity INTEGER,\n",
    "        total_amount DECIMAL(12,2),\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute schema creation\n",
    "    conn.execute(raw_table_ddl)\n",
    "    conn.execute(monthly_revenue_ddl)\n",
    "    conn.execute(daily_orders_ddl)\n",
    "    \n",
    "    print(f\"‚úÖ DuckDB connection established: {config['duckdb_file']}\")\n",
    "    print(f\"‚úÖ Created table: {config['tables']['raw_data']}\")\n",
    "    print(f\"‚úÖ Created table: {config['tables']['monthly_revenue']}\")  \n",
    "    print(f\"‚úÖ Created table: {config['tables']['daily_orders']}\")\n",
    "    \n",
    "    return conn\n",
    "\n",
    "# Create database connection and schema\n",
    "conn = create_duckdb_schema(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbfad3",
   "metadata": {},
   "source": [
    "## üì• Step 1.5: Load and Clean Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a844678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading Amazon sales data...\n",
      "‚úÖ Loaded 128,975 records from Amazon Sale Report.csv\n",
      "üßπ Applying data cleaning pipeline...\n",
      "‚úÖ Cleaned 7566 cancelled orders (Amount ‚Üí 0)\n",
      "‚úÖ Set default currency for 7795 records\n",
      "‚ö†Ô∏è  Flagged 229 non-cancelled orders with missing Amount\n",
      "üìä Final Amount nulls: 229\n",
      "\n",
      "üìä CLEANING SUMMARY:\n",
      "Metric                         Before     After     \n",
      "--------------------------------------------------\n",
      "Amount nulls                   7795       229       \n",
      "Currency nulls                 7795       0         \n",
      "Cancelled orders fixed         -          7566      \n",
      "Records flagged                -          229       \n",
      "\n",
      "üìà DATASET INFO:\n",
      "‚Ä¢ Total records: 128,975\n",
      "‚Ä¢ Columns: 25\n",
      "‚úÖ Loaded 128,975 records from Amazon Sale Report.csv\n",
      "üßπ Applying data cleaning pipeline...\n",
      "‚úÖ Cleaned 7566 cancelled orders (Amount ‚Üí 0)\n",
      "‚úÖ Set default currency for 7795 records\n",
      "‚ö†Ô∏è  Flagged 229 non-cancelled orders with missing Amount\n",
      "üìä Final Amount nulls: 229\n",
      "\n",
      "üìä CLEANING SUMMARY:\n",
      "Metric                         Before     After     \n",
      "--------------------------------------------------\n",
      "Amount nulls                   7795       229       \n",
      "Currency nulls                 7795       0         \n",
      "Cancelled orders fixed         -          7566      \n",
      "Records flagged                -          229       \n",
      "\n",
      "üìà DATASET INFO:\n",
      "‚Ä¢ Total records: 128,975\n",
      "‚Ä¢ Columns: 25\n",
      "‚Ä¢ Memory usage: 187.4 MB\n",
      "‚Ä¢ Processing time: 2.0 seconds\n",
      "\n",
      "üîç CLEANED DATA PREVIEW:\n",
      "‚Ä¢ Memory usage: 187.4 MB\n",
      "‚Ä¢ Processing time: 2.0 seconds\n",
      "\n",
      "üîç CLEANED DATA PREVIEW:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Order ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Fulfilment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sales Channel ",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ship-service-level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Style",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ASIN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Courier Status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Qty",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "currency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ship-city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ship-state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ship-postal-code",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ship-country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "promotion-ids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "B2B",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fulfilled-by",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Unnamed: 22",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data_quality_flag",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "2c338f6d-bd2f-4331-b159-118d94f78df9",
       "rows": [
        [
         "0",
         "0",
         "405-8078784-5731545",
         "2022-04-30 00:00:00",
         "Cancelled",
         "Merchant",
         "Amazon.in",
         "Standard",
         "SET389",
         "SET389-KR-NP-S",
         "Set",
         "S",
         "B09KXVBD7Z",
         null,
         "0",
         "INR",
         "647.62",
         "MUMBAI",
         "MAHARASHTRA",
         "400081.0",
         "IN",
         null,
         "False",
         "Easy Ship",
         null,
         null
        ],
        [
         "1",
         "1",
         "171-9198151-1101146",
         "2022-04-30 00:00:00",
         "Shipped - Delivered to Buyer",
         "Merchant",
         "Amazon.in",
         "Standard",
         "JNE3781",
         "JNE3781-KR-XXXL",
         "kurta",
         "3XL",
         "B09K3WFS32",
         "Shipped",
         "1",
         "INR",
         "406.0",
         "BENGALURU",
         "KARNATAKA",
         "560085.0",
         "IN",
         "Amazon PLCC Free-Financing Universal Merchant AAT-WNKTBO3K27EJC,Amazon PLCC Free-Financing Universal Merchant AAT-QX3UCCJESKPA2,Amazon PLCC Free-Financing Universal Merchant AAT-5QQ7BIYYQEDN2,Amazon PLCC Free-Financing Universal Merchant AAT-DSJ2QRXXWXVMQ,Amazon PLCC Free-Financing Universal Merchant AAT-CXJHMC2YJUK76,Amazon PLCC Free-Financing Universal Merchant AAT-CC4FAVTYR4X7C,Amazon PLCC Free-Financing Universal Merchant AAT-XXRCW6NZEPZI4,Amazon PLCC Free-Financing Universal Merchant AAT-CXNSLNBROFDW4,Amazon PLCC Free-Financing Universal Merchant AAT-R7GXNZWISTRFA,Amazon PLCC Free-Financing Universal Merchant AAT-WSJLDN3X7KEMO,Amazon PLCC Free-Financing Universal Merchant AAT-VL6FGQVGQVXUS,Amazon PLCC Free-Financing Universal Merchant AAT-EOKPWFWYW7Y6I,Amazon PLCC Free-Financing Universal Merchant AAT-ZYL5UPUNW6T62,Amazon PLCC Free-Financing Universal Merchant AAT-XVPICCHRWDCAI,Amazon PLCC Free-Financing Universal Merchant AAT-ETXQ3XXWMRXBG,Amazon PLCC Free-Financing Universal Merchant AAT-7X3XCTYG64VBE,Amazon PLCC Free-Financing Universal Merchant AAT-7CHGD3WTS3MHM,Amazon PLCC Free-Financing Universal Merchant AAT-26ZDKNME27X42,Amazon PLCC Free-Financing Universal Merchant AAT-4ZF5KN6E4LJK4,Amazon PLCC Free-Financing Universal Merchant AAT-7RCXIKUAX7DDY,Amazon PLCC Free-Financing Universal Merchant AAT-BRSZZ45H6MHAO,Amazon PLCC Free-Financing Universal Merchant AAT-MKLXOOZWQL7GO,Amazon PLCC Free-Financing Universal Merchant AAT-CB7UNXEXGIJTC,Amazon PLCC Free-Financing Universal Merchant #MP-gzasho-1593152694811,Amazon PLCC Free-Financing Universal Merchant AAT-WLBA4GZ52EAH4",
         "False",
         "Easy Ship",
         null,
         null
        ],
        [
         "2",
         "2",
         "404-0687676-7273146",
         "2022-04-30 00:00:00",
         "Shipped",
         "Amazon",
         "Amazon.in",
         "Expedited",
         "JNE3371",
         "JNE3371-KR-XL",
         "kurta",
         "XL",
         "B07WV4JV4D",
         "Shipped",
         "1",
         "INR",
         "329.0",
         "NAVI MUMBAI",
         "MAHARASHTRA",
         "410210.0",
         "IN",
         "IN Core Free Shipping 2015/04/08 23-48-5-108",
         "True",
         null,
         null,
         null
        ],
        [
         "3",
         "3",
         "403-9615377-8133951",
         "2022-04-30 00:00:00",
         "Cancelled",
         "Merchant",
         "Amazon.in",
         "Standard",
         "J0341",
         "J0341-DR-L",
         "Western Dress",
         "L",
         "B099NRCT7B",
         null,
         "0",
         "INR",
         "753.33",
         "PUDUCHERRY",
         "PUDUCHERRY",
         "605008.0",
         "IN",
         null,
         "False",
         "Easy Ship",
         null,
         null
        ],
        [
         "4",
         "4",
         "407-1069790-7240320",
         "2022-04-30 00:00:00",
         "Shipped",
         "Amazon",
         "Amazon.in",
         "Expedited",
         "JNE3671",
         "JNE3671-TU-XXXL",
         "Top",
         "3XL",
         "B098714BZP",
         "Shipped",
         "1",
         "INR",
         "574.0",
         "CHENNAI",
         "TAMIL NADU",
         "600073.0",
         "IN",
         null,
         "False",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Fulfilment</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>ship-service-level</th>\n",
       "      <th>Style</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Category</th>\n",
       "      <th>...</th>\n",
       "      <th>Amount</th>\n",
       "      <th>ship-city</th>\n",
       "      <th>ship-state</th>\n",
       "      <th>ship-postal-code</th>\n",
       "      <th>ship-country</th>\n",
       "      <th>promotion-ids</th>\n",
       "      <th>B2B</th>\n",
       "      <th>fulfilled-by</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>data_quality_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>405-8078784-5731545</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Amazon.in</td>\n",
       "      <td>Standard</td>\n",
       "      <td>SET389</td>\n",
       "      <td>SET389-KR-NP-S</td>\n",
       "      <td>Set</td>\n",
       "      <td>...</td>\n",
       "      <td>647.62</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>400081.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Easy Ship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>171-9198151-1101146</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Shipped - Delivered to Buyer</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Amazon.in</td>\n",
       "      <td>Standard</td>\n",
       "      <td>JNE3781</td>\n",
       "      <td>JNE3781-KR-XXXL</td>\n",
       "      <td>kurta</td>\n",
       "      <td>...</td>\n",
       "      <td>406.00</td>\n",
       "      <td>BENGALURU</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>560085.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>Amazon PLCC Free-Financing Universal Merchant ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Easy Ship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>404-0687676-7273146</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon.in</td>\n",
       "      <td>Expedited</td>\n",
       "      <td>JNE3371</td>\n",
       "      <td>JNE3371-KR-XL</td>\n",
       "      <td>kurta</td>\n",
       "      <td>...</td>\n",
       "      <td>329.00</td>\n",
       "      <td>NAVI MUMBAI</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>410210.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN Core Free Shipping 2015/04/08 23-48-5-108</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>403-9615377-8133951</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Amazon.in</td>\n",
       "      <td>Standard</td>\n",
       "      <td>J0341</td>\n",
       "      <td>J0341-DR-L</td>\n",
       "      <td>Western Dress</td>\n",
       "      <td>...</td>\n",
       "      <td>753.33</td>\n",
       "      <td>PUDUCHERRY</td>\n",
       "      <td>PUDUCHERRY</td>\n",
       "      <td>605008.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Easy Ship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>407-1069790-7240320</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon.in</td>\n",
       "      <td>Expedited</td>\n",
       "      <td>JNE3671</td>\n",
       "      <td>JNE3671-TU-XXXL</td>\n",
       "      <td>Top</td>\n",
       "      <td>...</td>\n",
       "      <td>574.00</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>600073.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             Order ID       Date                        Status  \\\n",
       "0      0  405-8078784-5731545 2022-04-30                     Cancelled   \n",
       "1      1  171-9198151-1101146 2022-04-30  Shipped - Delivered to Buyer   \n",
       "2      2  404-0687676-7273146 2022-04-30                       Shipped   \n",
       "3      3  403-9615377-8133951 2022-04-30                     Cancelled   \n",
       "4      4  407-1069790-7240320 2022-04-30                       Shipped   \n",
       "\n",
       "  Fulfilment Sales Channel  ship-service-level    Style              SKU  \\\n",
       "0   Merchant      Amazon.in           Standard   SET389   SET389-KR-NP-S   \n",
       "1   Merchant      Amazon.in           Standard  JNE3781  JNE3781-KR-XXXL   \n",
       "2     Amazon      Amazon.in          Expedited  JNE3371    JNE3371-KR-XL   \n",
       "3   Merchant      Amazon.in           Standard    J0341       J0341-DR-L   \n",
       "4     Amazon      Amazon.in          Expedited  JNE3671  JNE3671-TU-XXXL   \n",
       "\n",
       "        Category  ...  Amount    ship-city   ship-state  ship-postal-code  \\\n",
       "0            Set  ...  647.62       MUMBAI  MAHARASHTRA          400081.0   \n",
       "1          kurta  ...  406.00    BENGALURU    KARNATAKA          560085.0   \n",
       "2          kurta  ...  329.00  NAVI MUMBAI  MAHARASHTRA          410210.0   \n",
       "3  Western Dress  ...  753.33   PUDUCHERRY   PUDUCHERRY          605008.0   \n",
       "4            Top  ...  574.00      CHENNAI   TAMIL NADU          600073.0   \n",
       "\n",
       "  ship-country                                      promotion-ids    B2B  \\\n",
       "0           IN                                                NaN  False   \n",
       "1           IN  Amazon PLCC Free-Financing Universal Merchant ...  False   \n",
       "2           IN       IN Core Free Shipping 2015/04/08 23-48-5-108   True   \n",
       "3           IN                                                NaN  False   \n",
       "4           IN                                                NaN  False   \n",
       "\n",
       "  fulfilled-by  Unnamed: 22 data_quality_flag  \n",
       "0    Easy Ship          NaN               NaN  \n",
       "1    Easy Ship          NaN               NaN  \n",
       "2          NaN          NaN               NaN  \n",
       "3    Easy Ship          NaN               NaN  \n",
       "4          NaN          NaN               NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CSV data with cleaning pipeline\n",
    "print(\"üì• Loading Amazon sales data...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Read CSV file\n",
    "df_raw = pd.read_csv(CONFIG['csv_file'])\n",
    "print(f\"‚úÖ Loaded {len(df_raw):,} records from {CONFIG['csv_file']}\")\n",
    "\n",
    "# Apply data cleaning\n",
    "df_clean, cleaning_stats = clean_amazon_sales_data(df_raw, CONFIG)\n",
    "\n",
    "# Display cleaning summary\n",
    "print(f\"\\nüìä CLEANING SUMMARY:\")\n",
    "print(f\"{'Metric':<30} {'Before':<10} {'After':<10}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Amount nulls':<30} {cleaning_stats['original_amount_nulls']:<10} {cleaning_stats['final_amount_nulls']:<10}\")\n",
    "print(f\"{'Currency nulls':<30} {cleaning_stats['currency_defaults_set']:<10} {cleaning_stats['final_currency_nulls']:<10}\")\n",
    "print(f\"{'Cancelled orders fixed':<30} {'-':<10} {cleaning_stats['cancelled_orders_fixed']:<10}\")\n",
    "print(f\"{'Records flagged':<30} {'-':<10} {cleaning_stats['non_cancelled_flagged']:<10}\")\n",
    "\n",
    "# Basic data info\n",
    "print(f\"\\nüìà DATASET INFO:\")\n",
    "print(f\"‚Ä¢ Total records: {len(df_clean):,}\")\n",
    "print(f\"‚Ä¢ Columns: {len(df_clean.columns)}\")\n",
    "print(f\"‚Ä¢ Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "print(f\"‚Ä¢ Processing time: {(datetime.now() - start_time).total_seconds():.1f} seconds\")\n",
    "\n",
    "# Preview cleaned data\n",
    "print(f\"\\nüîç CLEANED DATA PREVIEW:\")\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f26a1",
   "metadata": {},
   "source": [
    "## üíæ Step 1.6: Ingest Data into DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ff440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Preparing data for DuckDB insertion...\n",
      "‚úÖ Prepared 128975 records with 22 columns\n",
      "üìã Columns: ['index_id', 'order_id', 'date_col', 'category', 'size', 'sku', 'asin', 'style', 'status', 'courier_status', 'qty', 'amount', 'currency', 'ship_service_level', 'ship_city', 'ship_state', 'ship_postal_code', 'ship_country', 'sales_channel', 'fulfilled_by', 'promotion_ids', 'data_quality_flag']\n",
      "\n",
      "üíæ Inserting data into DuckDB...\n",
      "‚úÖ Prepared 128975 records with 22 columns\n",
      "üìã Columns: ['index_id', 'order_id', 'date_col', 'category', 'size', 'sku', 'asin', 'style', 'status', 'courier_status', 'qty', 'amount', 'currency', 'ship_service_level', 'ship_city', 'ship_state', 'ship_postal_code', 'ship_country', 'sales_channel', 'fulfilled_by', 'promotion_ids', 'data_quality_flag']\n",
      "\n",
      "üíæ Inserting data into DuckDB...\n",
      "‚úÖ Successfully inserted 128,975 records\n",
      "‚è±Ô∏è  Insert time: 1.90 seconds\n",
      "üîç Verification: 128,975 records in DuckDB table\n",
      "‚úÖ Successfully inserted 128,975 records\n",
      "‚è±Ô∏è  Insert time: 1.90 seconds\n",
      "üîç Verification: 128,975 records in DuckDB table\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for DuckDB insertion\n",
    "def prepare_for_duckdb(df, config):\n",
    "    \"\"\"Prepare DataFrame for DuckDB insertion with proper column mapping\"\"\"\n",
    "    \n",
    "    # Create column mapping for DuckDB schema\n",
    "    df_db = df.copy()\n",
    "    \n",
    "    # Rename columns to match DuckDB schema\n",
    "    column_mapping = {\n",
    "        'index': 'index_id',\n",
    "        'Order ID': 'order_id', \n",
    "        'Date': 'date_col',\n",
    "        'Status': 'status',\n",
    "        'Fulfilment': 'fulfilled_by',\n",
    "        'Sales Channel ': 'sales_channel',\n",
    "        'ship-service-level': 'ship_service_level',\n",
    "        'Style': 'style',\n",
    "        'SKU': 'sku',\n",
    "        'Category': 'category',\n",
    "        'Size': 'size',\n",
    "        'ASIN': 'asin',\n",
    "        'Courier Status': 'courier_status',\n",
    "        'Qty': 'qty',\n",
    "        'currency': 'currency',\n",
    "        'Amount': 'amount',\n",
    "        'ship-city': 'ship_city',\n",
    "        'ship-state': 'ship_state',\n",
    "        'ship-postal-code': 'ship_postal_code',\n",
    "        'ship-country': 'ship_country',\n",
    "        'promotion-ids': 'promotion_ids'\n",
    "    }\n",
    "    \n",
    "    # Rename columns that exist in the DataFrame\n",
    "    existing_renames = {old: new for old, new in column_mapping.items() if old in df_db.columns}\n",
    "    df_db = df_db.rename(columns=existing_renames)\n",
    "    \n",
    "    # Select only columns that exist in DuckDB schema\n",
    "    db_columns = ['index_id', 'order_id', 'date_col', 'category', 'size', 'sku', 'asin', 'style',\n",
    "                  'status', 'courier_status', 'qty', 'amount', 'currency', 'ship_service_level', \n",
    "                  'ship_city', 'ship_state', 'ship_postal_code', 'ship_country', 'sales_channel',\n",
    "                  'fulfilled_by', 'promotion_ids', 'data_quality_flag']\n",
    "    \n",
    "    # Keep only columns that exist in both DataFrame and schema\n",
    "    available_columns = [col for col in db_columns if col in df_db.columns]\n",
    "    df_final = df_db[available_columns].copy()\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Prepare and insert data\n",
    "print(\"üíæ Preparing data for DuckDB insertion...\")\n",
    "df_for_db = prepare_for_duckdb(df_clean, CONFIG)\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(df_for_db)} records with {len(df_for_db.columns)} columns\")\n",
    "print(f\"üìã Columns: {list(df_for_db.columns)}\")\n",
    "\n",
    "# Insert data into DuckDB\n",
    "print(\"\\nüíæ Inserting data into DuckDB...\")\n",
    "insert_start = datetime.now()\n",
    "\n",
    "# Use DuckDB's efficient bulk insert\n",
    "conn.register('df_temp', df_for_db)\n",
    "# Insert only the columns we have (excluding ingestion_timestamp which has DEFAULT)\n",
    "column_list = ', '.join(df_for_db.columns)\n",
    "conn.execute(f\"INSERT INTO {CONFIG['tables']['raw_data']} ({column_list}) SELECT * FROM df_temp\")\n",
    "\n",
    "insert_time = (datetime.now() - insert_start).total_seconds()\n",
    "print(f\"‚úÖ Successfully inserted {len(df_for_db):,} records\")\n",
    "print(f\"‚è±Ô∏è  Insert time: {insert_time:.2f} seconds\")\n",
    "\n",
    "# Verify insertion\n",
    "count_result = conn.execute(f\"SELECT COUNT(*) FROM {CONFIG['tables']['raw_data']}\").fetchone()\n",
    "print(f\"üîç Verification: {count_result[0]:,} records in DuckDB table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b300ae",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 1.7: Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d97e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running data quality validation...\n",
      "==================================================\n",
      "üìä BASIC STATISTICS:\n",
      "‚Ä¢ Total records: 128,975\n",
      "‚Ä¢ Unique orders: 120,378\n",
      "‚Ä¢ Null amounts: 229\n",
      "‚Ä¢ Null currency: 0\n",
      "‚Ä¢ Flagged records: 229\n",
      "\n",
      "üìà BUSINESS VALIDATION BY STATUS:\n",
      "Status                    Count      Total $      Avg $      Date Range\n",
      "--------------------------------------------------------------------------------\n",
      "Shipped                   77,804     $50,324,255  $649       2022-03-31 to 2022-06-29\n",
      "Shipped - Delivered to Buyer 28,769     $18,650,815  $648       2022-03-31 to 2022-06-26\n",
      "Cancelled                 18,332     $6,919,284   $377       2022-03-31 to 2022-06-29\n",
      "Shipped - Returned to Seller 1,953      $1,269,644   $651       2022-03-31 to 2022-06-22\n",
      "Shipped - Picked Up       973        $661,252     $680       2022-04-06 to 2022-06-27\n",
      "Pending                   658        $430,271     $656       2022-04-04 to 2022-06-29\n",
      "Pending - Waiting for Pick Up 281        $192,138     $684       2022-06-27 to 2022-06-28\n",
      "Shipped - Returning to Seller 145        $107,620     $742       2022-04-10 to 2022-06-26\n",
      "Shipped - Out for Delivery 35         $26,971      $771       2022-04-21 to 2022-06-25\n",
      "Shipped - Rejected by Buyer 11         $7,295       $663       2022-04-04 to 2022-06-27\n",
      "Shipping                  8          $0           $0         2022-06-15 to 2022-06-15\n",
      "Shipped - Lost in Transit 5          $1,997       $399       2022-04-28 to 2022-05-29\n",
      "Shipped - Damaged         1          $1,136       $1136      2022-06-19 to 2022-06-19\n",
      "\n",
      "üè∑Ô∏è  TOP CATEGORIES BY REVENUE:\n",
      "Category             Orders     Revenue\n",
      "----------------------------------------\n",
      "Set                  46,029     $39,204,124\n",
      "kurta                45,859     $21,299,547\n",
      "Western Dress        14,473     $11,216,073\n",
      "Top                  9,991      $5,347,792\n",
      "Ethnic Dress         1,061      $791,218\n",
      "Blouse               859        $458,408\n",
      "Bottom               408        $150,668\n",
      "Saree                154        $123,934\n",
      "Dupatta              3          $915\n",
      "\n",
      "üéØ DATA QUALITY SCORE: 99.6%\n",
      "\n",
      "‚úÖ EXCELLENT data quality - Ready for analytical processing!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data quality validation\n",
    "def validate_data_quality(conn, config):\n",
    "    \"\"\"Run quality checks on ingested data\"\"\"\n",
    "    \n",
    "    table_name = config['tables']['raw_data']\n",
    "    \n",
    "    print(\"üîç Running data quality validation...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic counts and nulls\n",
    "    basic_stats = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_records,\n",
    "            COUNT(DISTINCT order_id) as unique_orders,\n",
    "            SUM(CASE WHEN amount IS NULL THEN 1 ELSE 0 END) as null_amounts,\n",
    "            SUM(CASE WHEN currency IS NULL THEN 1 ELSE 0 END) as null_currency,\n",
    "            SUM(CASE WHEN data_quality_flag IS NOT NULL THEN 1 ELSE 0 END) as flagged_records\n",
    "        FROM {table_name}\n",
    "    \"\"\").fetchone()\n",
    "    \n",
    "    print(f\"üìä BASIC STATISTICS:\")\n",
    "    print(f\"‚Ä¢ Total records: {basic_stats[0]:,}\")\n",
    "    print(f\"‚Ä¢ Unique orders: {basic_stats[1]:,}\")\n",
    "    print(f\"‚Ä¢ Null amounts: {basic_stats[2]:,}\")\n",
    "    print(f\"‚Ä¢ Null currency: {basic_stats[3]:,}\")\n",
    "    print(f\"‚Ä¢ Flagged records: {basic_stats[4]:,}\")\n",
    "    \n",
    "    # Business validation\n",
    "    business_stats = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            status,\n",
    "            COUNT(*) as order_count,\n",
    "            SUM(amount) as total_amount,\n",
    "            AVG(amount) as avg_amount,\n",
    "            MIN(date_col) as earliest_date,\n",
    "            MAX(date_col) as latest_date\n",
    "        FROM {table_name}\n",
    "        GROUP BY status\n",
    "        ORDER BY order_count DESC\n",
    "    \"\"\").fetchall()\n",
    "    \n",
    "    print(f\"\\nüìà BUSINESS VALIDATION BY STATUS:\")\n",
    "    print(f\"{'Status':<25} {'Count':<10} {'Total $':<12} {'Avg $':<10} {'Date Range'}\")\n",
    "    print(\"-\" * 80)\n",
    "    for row in business_stats:\n",
    "        status, count, total, avg, min_date, max_date = row\n",
    "        total_str = f\"${total:,.0f}\" if total else \"$0\"\n",
    "        avg_str = f\"${avg:.0f}\" if avg else \"$0\"\n",
    "        print(f\"{status:<25} {count:<10,} {total_str:<12} {avg_str:<10} {min_date} to {max_date}\")\n",
    "    \n",
    "    # Category analysis\n",
    "    category_stats = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            category,\n",
    "            COUNT(*) as order_count,\n",
    "            SUM(amount) as total_revenue\n",
    "        FROM {table_name}\n",
    "        WHERE amount > 0\n",
    "        GROUP BY category\n",
    "        ORDER BY total_revenue DESC\n",
    "        LIMIT 10\n",
    "    \"\"\").fetchall()\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è  TOP CATEGORIES BY REVENUE:\")\n",
    "    print(f\"{'Category':<20} {'Orders':<10} {'Revenue'}\")\n",
    "    print(\"-\" * 40)\n",
    "    for row in category_stats:\n",
    "        category, count, revenue = row\n",
    "        print(f\"{category:<20} {count:<10,} ${revenue:,.0f}\")\n",
    "    \n",
    "    # Quality score\n",
    "    quality_issues = basic_stats[2] + basic_stats[3] + basic_stats[4]  # nulls + flags\n",
    "    quality_score = max(0, 100 - (quality_issues / basic_stats[0] * 100))\n",
    "    \n",
    "    print(f\"\\nüéØ DATA QUALITY SCORE: {quality_score:.1f}%\")\n",
    "    \n",
    "    return quality_score\n",
    "\n",
    "# Run validation\n",
    "quality_score = validate_data_quality(conn, CONFIG)\n",
    "\n",
    "if quality_score >= 95:\n",
    "    print(\"\\n‚úÖ EXCELLENT data quality - Ready for analytical processing!\")\n",
    "elif quality_score >= 85:\n",
    "    print(\"\\n‚ö†Ô∏è  GOOD data quality - Minor issues detected\")\n",
    "else:\n",
    "    print(\"\\n‚ùå POOR data quality - Review required before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0025a76",
   "metadata": {},
   "source": [
    "## üéØ Step 1.8: Ingestion Summary & Next Steps\n",
    "\n",
    "**Stage 1 Data Ingestion COMPLETE!** \n",
    "\n",
    "‚úÖ **Achievements:**\n",
    "- Loaded and cleaned 128,975+ sales records\n",
    "- Applied business logic for missing values  \n",
    "- Created optimized DuckDB schema\n",
    "- Achieved high data quality score\n",
    "- Ready for Stage 2 analytical processing\n",
    "\n",
    "**Next Pipeline Steps:**\n",
    "- **Stage 2**: Create analytical tables (monthly revenue by category, daily orders by status)\n",
    "- **Stage 3**: Generate business intelligence visualizations\n",
    "- **Stage 4**: Implement Dagster orchestration framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0993bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DuckDB connection closed - file lock released\n"
     ]
    }
   ],
   "source": [
    "# Close DuckDB connection to release file lock for other notebooks\n",
    "if 'conn' in locals():\n",
    "    conn.close()\n",
    "    print(\"‚úÖ DuckDB connection closed - file lock released\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No connection to close\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verihub-dagster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
