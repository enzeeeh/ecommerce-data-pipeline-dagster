{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545f2bd0",
   "metadata": {},
   "source": [
    "# üìä Stage 2: Analytical Processing Pipeline\n",
    "## DuckDB Analytics ‚Üí Business Intelligence Tables\n",
    "\n",
    "**Objective**: Transform raw Amazon sales data into actionable business intelligence tables\n",
    "\n",
    "**Key Deliverables**:\n",
    "- ‚úÖ Monthly revenue by category analytical table\n",
    "- ‚úÖ Daily orders by status tracking table  \n",
    "- ‚úÖ Key performance indicators (KPIs)\n",
    "- ‚úÖ Summary statistics and business insights\n",
    "- ‚úÖ Data validation and quality assurance\n",
    "\n",
    "**Business Questions Answered**:\n",
    "1. **Monthly Revenue Trends**: Which categories drive the most revenue each month?\n",
    "2. **Order Status Analysis**: How do daily order patterns vary by fulfillment status?\n",
    "3. **Performance Metrics**: What are our key business KPIs and growth trends?\n",
    "\n",
    "**Dependencies**: Requires completed Stage 1 (Data Ingestion) with populated `amazon_sales_raw` table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f560971",
   "metadata": {},
   "source": [
    "## üì¶ Step 2.1: Import Required Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b942dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Required libraries imported successfully\n",
      "üìä Pandas version: 2.3.3\n",
      "ü¶Ü DuckDB version: 1.4.2\n",
      "‚öôÔ∏è Configuration loaded from Stage 1\n"
     ]
    }
   ],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization libraries for KPI outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utility libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Required libraries imported successfully\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"ü¶Ü DuckDB version: {duckdb.__version__}\")\n",
    "\n",
    "# Load configuration from Stage 1 (reuse same config)\n",
    "CONFIG = {\n",
    "    # File paths\n",
    "    'csv_file': 'Amazon Sale Report.csv',\n",
    "    'duckdb_file': 'amazon_sales.duckdb',\n",
    "    \n",
    "    # Key business columns\n",
    "    'business_columns': {\n",
    "        'date_col': 'date_col',      # Already converted in Stage 1\n",
    "        'amount_col': 'amount', \n",
    "        'category_col': 'category',\n",
    "        'status_col': 'status',\n",
    "        'courier_status_col': 'courier_status',\n",
    "        'currency_col': 'currency'\n",
    "    },\n",
    "    \n",
    "    # DuckDB table names\n",
    "    'tables': {\n",
    "        'raw_data': 'amazon_sales_raw',\n",
    "        'monthly_revenue': 'monthly_revenue_by_category',\n",
    "        'daily_orders': 'daily_orders_by_status'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration loaded from Stage 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4b580",
   "metadata": {},
   "source": [
    "## ü¶Ü Step 2.2: Connect to DuckDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448f3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connecting to DuckDB database...\n",
      "‚úÖ Connected via ATTACH method (avoiding file locks)\n",
      "‚úÖ Connected to database: amazon_sales.duckdb\n",
      "‚úÖ Raw data table found: 128,975 records\n",
      "üìÖ Date range: 2022-03-31 to 2022-06-29 (91 unique dates)\n",
      "üìä Data quality: 229 flagged records out of 128,975 total (0.2%)\n",
      "üéØ Ready to begin analytical processing!\n",
      "‚úÖ Connected via ATTACH method (avoiding file locks)\n",
      "‚úÖ Connected to database: amazon_sales.duckdb\n",
      "‚úÖ Raw data table found: 128,975 records\n",
      "üìÖ Date range: 2022-03-31 to 2022-06-29 (91 unique dates)\n",
      "üìä Data quality: 229 flagged records out of 128,975 total (0.2%)\n",
      "üéØ Ready to begin analytical processing!\n"
     ]
    }
   ],
   "source": [
    "# Connect to existing DuckDB database from Stage 1\n",
    "print(\"üîå Connecting to DuckDB database...\")\n",
    "\n",
    "# Close any existing connections first\n",
    "try:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"üîÑ Closed existing connection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Verify database file exists\n",
    "db_path = Path(CONFIG['duckdb_file'])\n",
    "if not db_path.exists():\n",
    "    print(f\"‚ùå Database file not found: {CONFIG['duckdb_file']}\")\n",
    "    print(\"‚ö†Ô∏è  Please run Stage 1 (Data Ingestion) first!\")\n",
    "    exit()\n",
    "\n",
    "# Establish connection - use in-memory connection and ATTACH to avoid lock issues\n",
    "try:\n",
    "    conn = duckdb.connect()  # In-memory connection\n",
    "    conn.execute(f\"ATTACH '{CONFIG['duckdb_file']}' AS main_db\")\n",
    "    print(\"‚úÖ Connected via ATTACH method (avoiding file locks)\")\n",
    "    \n",
    "    # Update table references to use attached database\n",
    "    CONFIG['tables']['raw_data'] = f\"main_db.{CONFIG['tables']['raw_data']}\"\n",
    "    CONFIG['tables']['monthly_revenue'] = f\"main_db.{CONFIG['tables']['monthly_revenue']}\"  \n",
    "    CONFIG['tables']['daily_orders'] = f\"main_db.{CONFIG['tables']['daily_orders']}\"\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to connect via ATTACH: {e}\")\n",
    "    # Fallback to direct connection\n",
    "    try:\n",
    "        conn = duckdb.connect(CONFIG['duckdb_file'])\n",
    "        print(\"‚úÖ Connected directly to database file\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå All connection methods failed: {e2}\")\n",
    "        exit()\n",
    "print(f\"‚úÖ Connected to database: {CONFIG['duckdb_file']}\")\n",
    "\n",
    "# Verify raw data table exists and check record count\n",
    "try:\n",
    "    raw_count = conn.execute(f\"SELECT COUNT(*) FROM {CONFIG['tables']['raw_data']}\").fetchone()[0]\n",
    "    print(f\"‚úÖ Raw data table found: {raw_count:,} records\")\n",
    "    \n",
    "    # Get date range of data\n",
    "    date_range = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            MIN(date_col) as earliest_date,\n",
    "            MAX(date_col) as latest_date,\n",
    "            COUNT(DISTINCT date_col) as unique_dates\n",
    "        FROM {CONFIG['tables']['raw_data']}\n",
    "    \"\"\").fetchone()\n",
    "    \n",
    "    print(f\"üìÖ Date range: {date_range[0]} to {date_range[1]} ({date_range[2]} unique dates)\")\n",
    "    \n",
    "    # Check data quality flags\n",
    "    quality_flags = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_records,\n",
    "            SUM(CASE WHEN data_quality_flag IS NOT NULL THEN 1 ELSE 0 END) as flagged_records\n",
    "        FROM {CONFIG['tables']['raw_data']}\n",
    "    \"\"\").fetchone()\n",
    "    \n",
    "    print(f\"üìä Data quality: {quality_flags[1]:,} flagged records out of {quality_flags[0]:,} total ({quality_flags[1]/quality_flags[0]*100:.1f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error accessing raw data table: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Please run Stage 1 (Data Ingestion) first!\")\n",
    "    exit()\n",
    "\n",
    "print(\"üéØ Ready to begin analytical processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc23ed",
   "metadata": {},
   "source": [
    "## üìà Step 2.3: Create Monthly Revenue by Category Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a1cd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Creating Monthly Revenue by Category table...\n",
      "‚úÖ Created 31 monthly category records\n",
      "‚è±Ô∏è  Processing time: 0.40 seconds\n",
      "\n",
      "üîç SAMPLE MONTHLY REVENUE DATA:\n",
      "Month    Category        Revenue      Orders   Avg Value\n",
      "------------------------------------------------------------\n",
      "2022-04  Set             $15,506,676  18,501   $838    \n",
      "2022-05  Set             $12,643,698  14,675   $862    \n",
      "2022-06  Set             $10,999,866  12,785   $860    \n",
      "2022-04  kurta           $8,017,145   18,182   $441    \n",
      "2022-05  kurta           $6,660,577   13,750   $484    \n",
      "2022-06  kurta           $6,587,568   13,853   $476    \n",
      "2022-05  Western Dress   $4,381,304   5,655    $775    \n",
      "2022-06  Western Dress   $3,899,334   4,911    $794    \n",
      "2022-04  Western Dress   $2,927,781   3,898    $751    \n",
      "2022-05  Top             $1,995,607   3,804    $525    \n",
      "\n",
      "üìä SUMMARY STATISTICS:\n",
      "‚Ä¢ Months covered: 4\n",
      "‚Ä¢ Categories covered: 9\n",
      "‚Ä¢ Total revenue: $78,592,678\n",
      "‚Ä¢ Total orders: 118,837\n",
      "‚úÖ Created 31 monthly category records\n",
      "‚è±Ô∏è  Processing time: 0.40 seconds\n",
      "\n",
      "üîç SAMPLE MONTHLY REVENUE DATA:\n",
      "Month    Category        Revenue      Orders   Avg Value\n",
      "------------------------------------------------------------\n",
      "2022-04  Set             $15,506,676  18,501   $838    \n",
      "2022-05  Set             $12,643,698  14,675   $862    \n",
      "2022-06  Set             $10,999,866  12,785   $860    \n",
      "2022-04  kurta           $8,017,145   18,182   $441    \n",
      "2022-05  kurta           $6,660,577   13,750   $484    \n",
      "2022-06  kurta           $6,587,568   13,853   $476    \n",
      "2022-05  Western Dress   $4,381,304   5,655    $775    \n",
      "2022-06  Western Dress   $3,899,334   4,911    $794    \n",
      "2022-04  Western Dress   $2,927,781   3,898    $751    \n",
      "2022-05  Top             $1,995,607   3,804    $525    \n",
      "\n",
      "üìä SUMMARY STATISTICS:\n",
      "‚Ä¢ Months covered: 4\n",
      "‚Ä¢ Categories covered: 9\n",
      "‚Ä¢ Total revenue: $78,592,678\n",
      "‚Ä¢ Total orders: 118,837\n"
     ]
    }
   ],
   "source": [
    "# Create Monthly Revenue by Category analytical table\n",
    "print(\"üìà Creating Monthly Revenue by Category table...\")\n",
    "\n",
    "# Clear existing data (for rerunability)\n",
    "conn.execute(f\"DELETE FROM {CONFIG['tables']['monthly_revenue']}\")\n",
    "\n",
    "# Build the analytical query\n",
    "monthly_revenue_query = f\"\"\"\n",
    "INSERT INTO {CONFIG['tables']['monthly_revenue']} \n",
    "(year_month, category, total_revenue, order_count, avg_order_value)\n",
    "SELECT \n",
    "    STRFTIME('%Y-%m', date_col) as year_month,\n",
    "    category,\n",
    "    ROUND(SUM(amount), 2) as total_revenue,\n",
    "    COUNT(*) as order_count,\n",
    "    ROUND(AVG(amount), 2) as avg_order_value\n",
    "FROM {CONFIG['tables']['raw_data']}\n",
    "WHERE amount > 0  -- Exclude $0 cancelled orders for revenue calculation\n",
    "  AND data_quality_flag IS NULL  -- Exclude flagged records\n",
    "GROUP BY \n",
    "    STRFTIME('%Y-%m', date_col),\n",
    "    category\n",
    "ORDER BY \n",
    "    year_month DESC, \n",
    "    total_revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the analytical transformation\n",
    "start_time = datetime.now()\n",
    "conn.execute(monthly_revenue_query)\n",
    "processing_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "# Verify the results\n",
    "monthly_count = conn.execute(f\"SELECT COUNT(*) FROM {CONFIG['tables']['monthly_revenue']}\").fetchone()[0]\n",
    "print(f\"‚úÖ Created {monthly_count} monthly category records\")\n",
    "print(f\"‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "\n",
    "# Display sample results\n",
    "print(f\"\\nüîç SAMPLE MONTHLY REVENUE DATA:\")\n",
    "sample_data = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        year_month, \n",
    "        category, \n",
    "        total_revenue, \n",
    "        order_count, \n",
    "        avg_order_value\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "    ORDER BY total_revenue DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"{'Month':<8} {'Category':<15} {'Revenue':<12} {'Orders':<8} {'Avg Value'}\")\n",
    "print(\"-\" * 60)\n",
    "for row in sample_data:\n",
    "    month, category, revenue, orders, avg_val = row\n",
    "    print(f\"{month:<8} {category:<15} ${revenue:<11,.0f} {orders:<8,} ${avg_val:<7.0f}\")\n",
    "\n",
    "# Get summary statistics\n",
    "summary_stats = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT year_month) as months_covered,\n",
    "        COUNT(DISTINCT category) as categories_covered,\n",
    "        SUM(total_revenue) as total_revenue_all,\n",
    "        SUM(order_count) as total_orders_all\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"\\nüìä SUMMARY STATISTICS:\")\n",
    "print(f\"‚Ä¢ Months covered: {summary_stats[0]}\")\n",
    "print(f\"‚Ä¢ Categories covered: {summary_stats[1]}\")\n",
    "print(f\"‚Ä¢ Total revenue: ${summary_stats[2]:,.0f}\")\n",
    "print(f\"‚Ä¢ Total orders: {summary_stats[3]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293e172",
   "metadata": {},
   "source": [
    "## üìä Step 2.4: Create Daily Orders by Status Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4334205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating Daily Orders by Status table...\n",
      "‚úÖ Created 456 daily status records\n",
      "‚è±Ô∏è  Processing time: 0.18 seconds\n",
      "\n",
      "üîç SAMPLE DAILY ORDERS DATA:\n",
      "Date         Status                    Orders   Qty    Amount\n",
      "----------------------------------------------------------------------\n",
      "<12 Pending                   453      454    $294,831 \n",
      "<12 Shipped                   173      173    $115,595 \n",
      "<12 Cancelled                 31       0      $1,105   \n",
      "<12 Shipped                   665      669    $444,275 \n",
      "<12 Pending - Waiting for Pick Up 252      254    $176,863 \n",
      "<12 Cancelled                 162      50     $59,927  \n",
      "<12 Pending                   131      131    $91,021  \n",
      "<12 Shipped                   660      660    $447,699 \n",
      "<12 Shipped - Picked Up       260      261    $179,301 \n",
      "<12 Cancelled                 140      51     $56,487  \n",
      "<12 Pending - Waiting for Pick Up 29       29     $15,275  \n",
      "<12 Pending                   21       21     $14,396  \n",
      "<12 Shipped - Rejected by Buyer 1        1      $967     \n",
      "<12 Shipped                   757      759    $511,069 \n",
      "<12 Shipped - Picked Up       272      274    $181,624 \n",
      "\n",
      "üìà STATUS DISTRIBUTION SUMMARY:\n",
      "Status                    Total Orders Avg Daily  Revenue\n",
      "-----------------------------------------------------------------\n",
      "Shipped                   77,596       852.7      $50,324,255\n",
      "Shipped - Delivered to Buyer 28,761       326.8      $18,650,815\n",
      "Cancelled                 18,332       201.5      $6,919,284\n",
      "Shipped - Returned to Seller 1,950        23.2       $1,269,644\n",
      "Shipped - Picked Up       973          38.9       $661,252 \n",
      "Pending                   656          32.8       $430,271 \n",
      "Pending - Waiting for Pick Up 281          140.5      $192,138 \n",
      "Shipped - Returning to Seller 145          5.2        $107,620 \n",
      "Shipped - Out for Delivery 35           2.7        $26,971  \n",
      "Shipped - Rejected by Buyer 11           1.1        $7,295   \n",
      "Shipped - Lost in Transit 5            1.7        $1,997   \n",
      "Shipped - Damaged         1            1.0        $1,136   \n",
      "\n",
      "üìÖ DAILY TRENDS SUMMARY:\n",
      "‚Ä¢ Days covered: 91\n",
      "‚Ä¢ Average orders per day/status: 282.3\n",
      "‚Ä¢ Date range: 2022-03-31 to 2022-06-29\n",
      "\n",
      "üìà STATUS DISTRIBUTION SUMMARY:\n",
      "Status                    Total Orders Avg Daily  Revenue\n",
      "-----------------------------------------------------------------\n",
      "Shipped                   77,596       852.7      $50,324,255\n",
      "Shipped - Delivered to Buyer 28,761       326.8      $18,650,815\n",
      "Cancelled                 18,332       201.5      $6,919,284\n",
      "Shipped - Returned to Seller 1,950        23.2       $1,269,644\n",
      "Shipped - Picked Up       973          38.9       $661,252 \n",
      "Pending                   656          32.8       $430,271 \n",
      "Pending - Waiting for Pick Up 281          140.5      $192,138 \n",
      "Shipped - Returning to Seller 145          5.2        $107,620 \n",
      "Shipped - Out for Delivery 35           2.7        $26,971  \n",
      "Shipped - Rejected by Buyer 11           1.1        $7,295   \n",
      "Shipped - Lost in Transit 5            1.7        $1,997   \n",
      "Shipped - Damaged         1            1.0        $1,136   \n",
      "\n",
      "üìÖ DAILY TRENDS SUMMARY:\n",
      "‚Ä¢ Days covered: 91\n",
      "‚Ä¢ Average orders per day/status: 282.3\n",
      "‚Ä¢ Date range: 2022-03-31 to 2022-06-29\n"
     ]
    }
   ],
   "source": [
    "# Create Daily Orders by Status analytical table\n",
    "print(\"üìä Creating Daily Orders by Status table...\")\n",
    "\n",
    "# Clear existing data (for rerunability)\n",
    "conn.execute(f\"DELETE FROM {CONFIG['tables']['daily_orders']}\")\n",
    "\n",
    "# Build the daily orders analytical query\n",
    "daily_orders_query = f\"\"\"\n",
    "INSERT INTO {CONFIG['tables']['daily_orders']} \n",
    "(order_date, status, order_count, total_quantity, total_amount)\n",
    "SELECT \n",
    "    date_col as order_date,\n",
    "    status,\n",
    "    COUNT(*) as order_count,\n",
    "    SUM(qty) as total_quantity,\n",
    "    ROUND(SUM(amount), 2) as total_amount\n",
    "FROM {CONFIG['tables']['raw_data']}\n",
    "WHERE data_quality_flag IS NULL  -- Exclude flagged records\n",
    "GROUP BY \n",
    "    date_col,\n",
    "    status\n",
    "ORDER BY \n",
    "    date_col DESC, \n",
    "    order_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the analytical transformation\n",
    "start_time = datetime.now()\n",
    "conn.execute(daily_orders_query)\n",
    "processing_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "# Verify the results\n",
    "daily_count = conn.execute(f\"SELECT COUNT(*) FROM {CONFIG['tables']['daily_orders']}\").fetchone()[0]\n",
    "print(f\"‚úÖ Created {daily_count} daily status records\")\n",
    "print(f\"‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "\n",
    "# Display sample results\n",
    "print(f\"\\nüîç SAMPLE DAILY ORDERS DATA:\")\n",
    "sample_data = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        order_date, \n",
    "        status, \n",
    "        order_count, \n",
    "        total_quantity, \n",
    "        total_amount\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "    ORDER BY order_date DESC, order_count DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"{'Date':<12} {'Status':<25} {'Orders':<8} {'Qty':<6} {'Amount'}\")\n",
    "print(\"-\" * 70)\n",
    "for row in sample_data:\n",
    "    date, status, count, qty, amount = row\n",
    "    print(f\"{date:<12} {status:<25} {count:<8,} {qty:<6,} ${amount:<8,.0f}\")\n",
    "\n",
    "# Get status distribution summary\n",
    "status_summary = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        status,\n",
    "        SUM(order_count) as total_orders,\n",
    "        AVG(order_count) as avg_daily_orders,\n",
    "        SUM(total_amount) as total_revenue\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "    GROUP BY status\n",
    "    ORDER BY total_orders DESC\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"\\nüìà STATUS DISTRIBUTION SUMMARY:\")\n",
    "print(f\"{'Status':<25} {'Total Orders':<12} {'Avg Daily':<10} {'Revenue'}\")\n",
    "print(\"-\" * 65)\n",
    "for row in status_summary:\n",
    "    status, total, avg, revenue = row\n",
    "    print(f\"{status:<25} {total:<12,} {avg:<10.1f} ${revenue:<8,.0f}\")\n",
    "\n",
    "# Get daily trends\n",
    "daily_trends = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT order_date) as days_covered,\n",
    "        AVG(order_count) as avg_orders_per_day_status,\n",
    "        MIN(order_date) as earliest_date,\n",
    "        MAX(order_date) as latest_date\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"\\nüìÖ DAILY TRENDS SUMMARY:\")\n",
    "print(f\"‚Ä¢ Days covered: {daily_trends[0]}\")\n",
    "print(f\"‚Ä¢ Average orders per day/status: {daily_trends[1]:.1f}\")\n",
    "print(f\"‚Ä¢ Date range: {daily_trends[2]} to {daily_trends[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7bdbf6",
   "metadata": {},
   "source": [
    "## üéØ Step 2.5: Generate Key Performance Indicators (KPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad86f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Calculating Key Performance Indicators...\n",
      "==================================================\n",
      "üí∞ OVERALL BUSINESS METRICS:\n",
      "‚Ä¢ Total Orders: 128,746\n",
      "‚Ä¢ Unique Orders: 120,255\n",
      "‚Ä¢ Total Revenue: $78,592,678\n",
      "‚Ä¢ Average Order Value: $661.35\n",
      "‚Ä¢ Total Quantity Sold: 116,483\n",
      "‚Ä¢ Categories Sold: 9\n",
      "‚Ä¢ Active Days: 91\n",
      "\n",
      "üì¶ ORDER FULFILLMENT METRICS:\n",
      "‚Ä¢ Successful Shipments: 107,516 (83.5%)\n",
      "‚Ä¢ Cancelled Orders: 18,332 (14.2%)\n",
      "‚Ä¢ Failed Deliveries: 1,961 (1.5%)\n",
      "‚Ä¢ Success Rate: 83.5%\n",
      "\n",
      "üèÜ TOP 5 CATEGORIES BY REVENUE:\n",
      "Category        Revenue      Orders   Avg Value\n",
      "---------------------------------------------\n",
      "Set             $39,204,124  46,029   $838    \n",
      "kurta           $21,299,547  45,859   $466    \n",
      "Western Dress   $11,216,073  14,473   $793    \n",
      "Top             $5,347,792   9,991    $534    \n",
      "Ethnic Dress    $791,218     1,061    $837    \n",
      "\n",
      "üìà MONTHLY GROWTH TRENDS:\n",
      "Month    Revenue      Orders   Growth %\n",
      "----------------------------------------\n",
      "2022-03  $101,684     162      baseline\n",
      "2022-04  $28,838,708  45,235   +28261.1%\n",
      "2022-05  $26,226,477  38,788   -9.1%\n",
      "2022-06  $23,425,809  34,652   -10.7%\n",
      "\n",
      "üó∫Ô∏è  TOP 10 STATES BY REVENUE:\n",
      "State                Orders   Revenue\n",
      "----------------------------------------\n",
      "MAHARASHTRA          20,639   $13,335,534\n",
      "KARNATAKA            16,064   $10,481,114\n",
      "TELANGANA            10,472   $6,916,616\n",
      "UTTAR PRADESH        9,708    $6,816,642\n",
      "TAMIL NADU           10,632   $6,515,650\n",
      "DELHI                6,222    $4,235,216\n",
      "KERALA               6,072    $3,830,228\n",
      "WEST BENGAL          5,437    $3,507,880\n",
      "ANDHRA PRADESH       4,993    $3,219,832\n",
      "HARYANA              4,086    $2,882,093\n",
      "\n",
      "‚úÖ KPI analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Generate Key Performance Indicators (KPIs)\n",
    "print(\"üéØ Calculating Key Performance Indicators...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# KPI 1: Overall Business Metrics\n",
    "overall_kpis = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_orders,\n",
    "        COUNT(DISTINCT order_id) as unique_orders,\n",
    "        SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END) as total_revenue,\n",
    "        AVG(CASE WHEN amount > 0 THEN amount ELSE NULL END) as avg_order_value,\n",
    "        SUM(qty) as total_quantity,\n",
    "        COUNT(DISTINCT category) as categories_sold,\n",
    "        COUNT(DISTINCT date_col) as active_days\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(\"üí∞ OVERALL BUSINESS METRICS:\")\n",
    "print(f\"‚Ä¢ Total Orders: {overall_kpis[0]:,}\")\n",
    "print(f\"‚Ä¢ Unique Orders: {overall_kpis[1]:,}\")\n",
    "print(f\"‚Ä¢ Total Revenue: ${overall_kpis[2]:,.0f}\")\n",
    "print(f\"‚Ä¢ Average Order Value: ${overall_kpis[3]:.2f}\")\n",
    "print(f\"‚Ä¢ Total Quantity Sold: {overall_kpis[4]:,}\")\n",
    "print(f\"‚Ä¢ Categories Sold: {overall_kpis[5]}\")\n",
    "print(f\"‚Ä¢ Active Days: {overall_kpis[6]}\")\n",
    "\n",
    "# KPI 2: Order Fulfillment Metrics\n",
    "fulfillment_kpis = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        SUM(CASE WHEN status LIKE '%Shipped%' AND status NOT LIKE '%Returned%' AND status NOT LIKE '%Rejected%' THEN 1 ELSE 0 END) as successful_shipments,\n",
    "        SUM(CASE WHEN status = 'Cancelled' THEN 1 ELSE 0 END) as cancelled_orders,\n",
    "        SUM(CASE WHEN status LIKE '%Returned%' OR status LIKE '%Rejected%' THEN 1 ELSE 0 END) as failed_deliveries,\n",
    "        COUNT(*) as total_processed\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "success_rate = (fulfillment_kpis[0] / fulfillment_kpis[3]) * 100\n",
    "cancellation_rate = (fulfillment_kpis[1] / fulfillment_kpis[3]) * 100\n",
    "return_rate = (fulfillment_kpis[2] / fulfillment_kpis[3]) * 100\n",
    "\n",
    "print(f\"\\nüì¶ ORDER FULFILLMENT METRICS:\")\n",
    "print(f\"‚Ä¢ Successful Shipments: {fulfillment_kpis[0]:,} ({success_rate:.1f}%)\")\n",
    "print(f\"‚Ä¢ Cancelled Orders: {fulfillment_kpis[1]:,} ({cancellation_rate:.1f}%)\")\n",
    "print(f\"‚Ä¢ Failed Deliveries: {fulfillment_kpis[2]:,} ({return_rate:.1f}%)\")\n",
    "print(f\"‚Ä¢ Success Rate: {success_rate:.1f}%\")\n",
    "\n",
    "# KPI 3: Top Performing Categories\n",
    "top_categories = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        SUM(total_revenue) as revenue,\n",
    "        SUM(order_count) as orders,\n",
    "        ROUND(AVG(avg_order_value), 2) as avg_value\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "    GROUP BY category\n",
    "    ORDER BY revenue DESC\n",
    "    LIMIT 5\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"\\nüèÜ TOP 5 CATEGORIES BY REVENUE:\")\n",
    "print(f\"{'Category':<15} {'Revenue':<12} {'Orders':<8} {'Avg Value'}\")\n",
    "print(\"-\" * 45)\n",
    "for row in top_categories:\n",
    "    category, revenue, orders, avg_val = row\n",
    "    print(f\"{category:<15} ${revenue:<11,.0f} {orders:<8,} ${avg_val:<7.0f}\")\n",
    "\n",
    "# KPI 4: Monthly Growth Trends\n",
    "monthly_trends = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        year_month,\n",
    "        SUM(total_revenue) as monthly_revenue,\n",
    "        SUM(order_count) as monthly_orders\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "    GROUP BY year_month\n",
    "    ORDER BY year_month\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"\\nüìà MONTHLY GROWTH TRENDS:\")\n",
    "print(f\"{'Month':<8} {'Revenue':<12} {'Orders':<8} {'Growth %'}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "prev_revenue = None\n",
    "for i, (month, revenue, orders) in enumerate(monthly_trends):\n",
    "    if prev_revenue is not None:\n",
    "        growth = ((revenue - prev_revenue) / prev_revenue) * 100\n",
    "        growth_str = f\"{growth:+.1f}%\"\n",
    "    else:\n",
    "        growth_str = \"baseline\"\n",
    "    \n",
    "    print(f\"{month:<8} ${revenue:<11,.0f} {orders:<8,} {growth_str}\")\n",
    "    prev_revenue = revenue\n",
    "\n",
    "# KPI 5: Geographic Distribution\n",
    "geo_distribution = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        ship_state,\n",
    "        COUNT(*) as orders,\n",
    "        SUM(amount) as revenue\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL \n",
    "      AND amount > 0\n",
    "      AND ship_state IS NOT NULL\n",
    "    GROUP BY ship_state\n",
    "    ORDER BY revenue DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è  TOP 10 STATES BY REVENUE:\")\n",
    "print(f\"{'State':<20} {'Orders':<8} {'Revenue'}\")\n",
    "print(\"-\" * 40)\n",
    "for row in geo_distribution:\n",
    "    state, orders, revenue = row\n",
    "    print(f\"{state:<20} {orders:<8,} ${revenue:,.0f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ KPI analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd10042",
   "metadata": {},
   "source": [
    "## üìã Step 2.6: Create Summary Statistics Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e7b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Creating additional analytical views...\n",
      "\n",
      "üó∫Ô∏è  Creating geographic distribution analysis...\n",
      "üöõ Creating courier performance analysis...\n",
      "üì¶ Creating product performance analysis...\n",
      "‚úÖ Analytical views created successfully!\n",
      "\n",
      "üìä SAMPLE GEOGRAPHIC DISTRIBUTION:\n",
      "State           Orders   Revenue      Avg Value\n",
      "---------------------------------------------\n",
      "KARNATAKA       11,215   $6,849,665   $654\n",
      "TELANGANA       8,058    $4,941,132   $661\n",
      "MAHARASHTRA     6,118    $3,704,462   $646\n",
      "DELHI           5,782    $3,608,137   $682\n",
      "TAMIL NADU      5,413    $3,098,746   $615\n",
      "MAHARASHTRA     3,852    $2,338,518   $654\n",
      "WEST BENGAL     2,379    $1,414,979   $643\n",
      "HARYANA         1,867    $1,221,619   $703\n",
      "\n",
      "üöõ SAMPLE COURIER PERFORMANCE:\n",
      "Courier Status Order Status              Count    Value\n",
      "------------------------------------------------------------\n",
      "Shipped      Shipped                   77,596   $50,324,255\n",
      "Shipped      Shipped - Delivered to Buyer 28,761   $18,650,815\n",
      "Unshipped    Cancelled                 5,631    $3,729,112\n",
      "Shipped      Shipped - Returned to Seller 1,950    $1,269,644\n",
      "Shipped      Shipped - Picked Up       973      $661,252 \n",
      "Unshipped    Pending                   646      $422,592 \n",
      "Unshipped    Pending - Waiting for Pick Up 281      $192,138 \n",
      "Shipped      Shipped - Returning to Seller 145      $107,620 \n",
      "\n",
      "üì¶ SAMPLE PRODUCT PERFORMANCE:\n",
      "Category        Orders   Revenue      Avg Price\n",
      "--------------------------------------------------\n",
      "Set             9,329    $7,304,158   $852     \n",
      "Set             8,181    $6,354,714   $847     \n",
      "Set             7,556    $5,936,974   $850     \n",
      "Set             7,486    $5,835,237   $859     \n",
      "Set             6,155    $4,765,516   $849     \n",
      "Set             5,788    $4,530,260   $841     \n",
      "Set             5,495    $4,261,846   $852     \n",
      "kurta           8,897    $3,729,873   $457     \n",
      "\n",
      "üìà ANALYTICAL VIEWS SUMMARY:\n",
      "‚Ä¢ Geographic distribution records: 9,148\n",
      "‚Ä¢ Courier performance records: 14\n",
      "‚Ä¢ Product performance records: 57\n",
      "\n",
      "üìà ANALYTICAL VIEWS SUMMARY:\n",
      "‚Ä¢ Geographic distribution records: 9,148\n",
      "‚Ä¢ Courier performance records: 14\n",
      "‚Ä¢ Product performance records: 57\n"
     ]
    }
   ],
   "source": [
    "# Create additional analytical views and summary statistics\n",
    "print(\"üìã Creating additional analytical views...\")\n",
    "\n",
    "# Create Customer Geographic Distribution view\n",
    "print(\"\\nüó∫Ô∏è  Creating geographic distribution analysis...\")\n",
    "geo_analysis = conn.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW geographic_distribution AS\n",
    "    SELECT \n",
    "        ship_state,\n",
    "        ship_city,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END) as total_revenue,\n",
    "        AVG(CASE WHEN amount > 0 THEN amount ELSE NULL END) as avg_order_value,\n",
    "        COUNT(DISTINCT category) as categories_purchased\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL\n",
    "      AND ship_state IS NOT NULL\n",
    "    GROUP BY ship_state, ship_city\n",
    "    ORDER BY total_revenue DESC;\n",
    "\"\"\")\n",
    "\n",
    "# Create Courier Performance Analysis view\n",
    "print(\"üöõ Creating courier performance analysis...\")\n",
    "courier_analysis = conn.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW courier_performance AS\n",
    "    SELECT \n",
    "        courier_status,\n",
    "        status,\n",
    "        COUNT(*) as shipment_count,\n",
    "        SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END) as total_value,\n",
    "        AVG(CASE WHEN amount > 0 THEN amount ELSE NULL END) as avg_shipment_value,\n",
    "        ROUND(\n",
    "            COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY courier_status), \n",
    "            2\n",
    "        ) as status_percentage\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL\n",
    "      AND courier_status IS NOT NULL\n",
    "    GROUP BY courier_status, status\n",
    "    ORDER BY courier_status, shipment_count DESC;\n",
    "\"\"\")\n",
    "\n",
    "# Create Product Performance Metrics view\n",
    "print(\"üì¶ Creating product performance analysis...\")\n",
    "product_analysis = conn.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW product_performance AS\n",
    "    SELECT \n",
    "        category,\n",
    "        size,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(qty) as total_quantity,\n",
    "        SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END) as total_revenue,\n",
    "        AVG(CASE WHEN amount > 0 THEN amount ELSE NULL END) as avg_price,\n",
    "        COUNT(DISTINCT ship_state) as states_shipped_to\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE data_quality_flag IS NULL\n",
    "    GROUP BY category, size\n",
    "    ORDER BY total_revenue DESC;\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Analytical views created successfully!\")\n",
    "\n",
    "# Display sample from each view\n",
    "print(f\"\\nüìä SAMPLE GEOGRAPHIC DISTRIBUTION:\")\n",
    "geo_sample = conn.execute(\"\"\"\n",
    "    SELECT ship_state, order_count, total_revenue, avg_order_value\n",
    "    FROM geographic_distribution \n",
    "    ORDER BY total_revenue DESC \n",
    "    LIMIT 8\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"{'State':<15} {'Orders':<8} {'Revenue':<12} {'Avg Value'}\")\n",
    "print(\"-\" * 45)\n",
    "for row in geo_sample:\n",
    "    state, orders, revenue, avg_val = row\n",
    "    avg_display = f\"${avg_val:.0f}\" if avg_val else \"N/A\"\n",
    "    print(f\"{state:<15} {orders:<8,} ${revenue:<11,.0f} {avg_display}\")\n",
    "\n",
    "print(f\"\\nüöõ SAMPLE COURIER PERFORMANCE:\")\n",
    "courier_sample = conn.execute(\"\"\"\n",
    "    SELECT courier_status, status, shipment_count, total_value\n",
    "    FROM courier_performance \n",
    "    ORDER BY total_value DESC \n",
    "    LIMIT 8\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"{'Courier Status':<12} {'Order Status':<25} {'Count':<8} {'Value'}\")\n",
    "print(\"-\" * 60)\n",
    "for row in courier_sample:\n",
    "    courier, status, count, value = row\n",
    "    print(f\"{courier:<12} {status:<25} {count:<8,} ${value:<8,.0f}\")\n",
    "\n",
    "print(f\"\\nüì¶ SAMPLE PRODUCT PERFORMANCE:\")\n",
    "product_sample = conn.execute(\"\"\"\n",
    "    SELECT category, order_count, total_revenue, avg_price\n",
    "    FROM product_performance \n",
    "    WHERE avg_price IS NOT NULL\n",
    "    ORDER BY total_revenue DESC \n",
    "    LIMIT 8\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(f\"{'Category':<15} {'Orders':<8} {'Revenue':<12} {'Avg Price'}\")\n",
    "print(\"-\" * 50)\n",
    "for row in product_sample:\n",
    "    category, orders, revenue, avg_price = row\n",
    "    print(f\"{category:<15} {orders:<8,} ${revenue:<11,.0f} ${avg_price:<8.0f}\")\n",
    "\n",
    "# Get view statistics\n",
    "view_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        (SELECT COUNT(*) FROM geographic_distribution) as geo_records,\n",
    "        (SELECT COUNT(*) FROM courier_performance) as courier_records,\n",
    "        (SELECT COUNT(*) FROM product_performance) as product_records\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"\\nüìà ANALYTICAL VIEWS SUMMARY:\")\n",
    "print(f\"‚Ä¢ Geographic distribution records: {view_stats[0]:,}\")\n",
    "print(f\"‚Ä¢ Courier performance records: {view_stats[1]:,}\")\n",
    "print(f\"‚Ä¢ Product performance records: {view_stats[2]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831415b7",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 2.7: Validate Analytical Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2214ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validating analytical tables...\n",
      "==================================================\n",
      "üí∞ REVENUE RECONCILIATION:\n",
      "‚Ä¢ Raw data revenue: $78,592,678.30\n",
      "‚Ä¢ Monthly aggregated revenue: $78,592,678.30\n",
      "‚Ä¢ Difference: $0.00\n",
      "‚Ä¢ ‚úÖ Revenue reconciliation: PASSED\n",
      "\n",
      "üìä ORDER COUNT RECONCILIATION:\n",
      "‚Ä¢ Raw data orders (amount > 0): 118,837\n",
      "‚Ä¢ Monthly aggregated orders: 118,837\n",
      "‚Ä¢ Daily aggregated orders (amount > 0): 128,744\n",
      "‚Ä¢ ‚úÖ Order count reconciliation: FAILED\n",
      "\n",
      "üìÖ DATE RANGE CONSISTENCY:\n",
      "‚Ä¢ Raw data range: 2022-03-31 to 2022-06-29\n",
      "‚Ä¢ Monthly data range: 2022-03 to 2022-06\n",
      "‚Ä¢ Daily data range: 2022-03-31 to 2022-06-29\n",
      "‚Ä¢ ‚úÖ Date range consistency: PASSED\n",
      "\n",
      "üîç DATA COMPLETENESS CHECK:\n",
      "‚Ä¢ Total raw records: 128,975\n",
      "‚Ä¢ Clean records processed: 128,746\n",
      "‚Ä¢ Flagged/excluded records: 229\n",
      "‚Ä¢ Categories: Raw=9, Monthly=9\n",
      "‚Ä¢ Statuses: Raw=13, Daily=12\n",
      "‚Ä¢ ‚úÖ Data completeness: FAILED\n",
      "\n",
      "üéØ BUSINESS LOGIC VALIDATION:\n",
      "‚Ä¢ Negative revenue records: 0\n",
      "‚Ä¢ Invalid monthly order counts: 0\n",
      "‚Ä¢ Invalid daily order counts: 0\n",
      "‚Ä¢ Invalid average order values: 0\n",
      "‚Ä¢ ‚úÖ Business logic validation: PASSED\n",
      "\n",
      "üéØ OVERALL VALIDATION RESULT:\n",
      "==================================================\n",
      "‚ö†Ô∏è  ‚ùå SOME VALIDATIONS FAILED!\n",
      "   Please review the failed validations above.\n",
      "üìä Validation Score: 60%\n"
     ]
    }
   ],
   "source": [
    "# Validate analytical tables against raw data\n",
    "print(\"‚úÖ Validating analytical tables...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Validation 1: Revenue Reconciliation\n",
    "print(\"üí∞ REVENUE RECONCILIATION:\")\n",
    "raw_revenue = conn.execute(f\"\"\"\n",
    "    SELECT SUM(amount) as total_revenue\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE amount > 0 AND data_quality_flag IS NULL\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "monthly_revenue_sum = conn.execute(f\"\"\"\n",
    "    SELECT SUM(total_revenue) as aggregated_revenue\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "revenue_diff = abs(raw_revenue - monthly_revenue_sum)\n",
    "revenue_match = revenue_diff < 0.01  # Allow for rounding differences\n",
    "\n",
    "print(f\"‚Ä¢ Raw data revenue: ${raw_revenue:,.2f}\")\n",
    "print(f\"‚Ä¢ Monthly aggregated revenue: ${monthly_revenue_sum:,.2f}\")\n",
    "print(f\"‚Ä¢ Difference: ${revenue_diff:,.2f}\")\n",
    "print(f\"‚Ä¢ ‚úÖ Revenue reconciliation: {'PASSED' if revenue_match else 'FAILED'}\")\n",
    "\n",
    "# Validation 2: Order Count Reconciliation\n",
    "print(f\"\\nüìä ORDER COUNT RECONCILIATION:\")\n",
    "raw_orders = conn.execute(f\"\"\"\n",
    "    SELECT COUNT(*) as total_orders\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE amount > 0 AND data_quality_flag IS NULL\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "monthly_orders_sum = conn.execute(f\"\"\"\n",
    "    SELECT SUM(order_count) as aggregated_orders\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "daily_orders_sum = conn.execute(f\"\"\"\n",
    "    SELECT SUM(order_count) as aggregated_orders\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "    WHERE total_amount > 0\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "orders_match = (raw_orders == monthly_orders_sum == daily_orders_sum)\n",
    "\n",
    "print(f\"‚Ä¢ Raw data orders (amount > 0): {raw_orders:,}\")\n",
    "print(f\"‚Ä¢ Monthly aggregated orders: {monthly_orders_sum:,}\")\n",
    "print(f\"‚Ä¢ Daily aggregated orders (amount > 0): {daily_orders_sum:,}\")\n",
    "print(f\"‚Ä¢ ‚úÖ Order count reconciliation: {'PASSED' if orders_match else 'FAILED'}\")\n",
    "\n",
    "# Validation 3: Date Range Consistency\n",
    "print(f\"\\nüìÖ DATE RANGE CONSISTENCY:\")\n",
    "raw_dates = conn.execute(f\"\"\"\n",
    "    SELECT MIN(date_col) as min_date, MAX(date_col) as max_date\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "monthly_dates = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        MIN(year_month || '-01') as min_month,\n",
    "        MAX(year_month || '-01') as max_month\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "daily_dates = conn.execute(f\"\"\"\n",
    "    SELECT MIN(order_date) as min_date, MAX(order_date) as max_date\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"‚Ä¢ Raw data range: {raw_dates[0]} to {raw_dates[1]}\")\n",
    "print(f\"‚Ä¢ Monthly data range: {monthly_dates[0][:7]} to {monthly_dates[1][:7]}\")\n",
    "print(f\"‚Ä¢ Daily data range: {daily_dates[0]} to {daily_dates[1]}\")\n",
    "\n",
    "date_consistency = (raw_dates[0] == daily_dates[0] and raw_dates[1] == daily_dates[1])\n",
    "print(f\"‚Ä¢ ‚úÖ Date range consistency: {'PASSED' if date_consistency else 'FAILED'}\")\n",
    "\n",
    "# Validation 4: Data Completeness Check\n",
    "print(f\"\\nüîç DATA COMPLETENESS CHECK:\")\n",
    "completeness_check = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_raw_records,\n",
    "        COUNT(CASE WHEN data_quality_flag IS NULL THEN 1 END) as clean_records,\n",
    "        COUNT(CASE WHEN data_quality_flag IS NOT NULL THEN 1 END) as flagged_records,\n",
    "        COUNT(DISTINCT category) as categories_in_raw,\n",
    "        (SELECT COUNT(DISTINCT category) FROM {CONFIG['tables']['monthly_revenue']}) as categories_in_monthly,\n",
    "        COUNT(DISTINCT status) as statuses_in_raw,\n",
    "        (SELECT COUNT(DISTINCT status) FROM {CONFIG['tables']['daily_orders']}) as statuses_in_daily\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "total_raw, clean_records, flagged_records, raw_categories, monthly_categories, raw_statuses, daily_statuses = completeness_check\n",
    "\n",
    "print(f\"‚Ä¢ Total raw records: {total_raw:,}\")\n",
    "print(f\"‚Ä¢ Clean records processed: {clean_records:,}\")\n",
    "print(f\"‚Ä¢ Flagged/excluded records: {flagged_records:,}\")\n",
    "print(f\"‚Ä¢ Categories: Raw={raw_categories}, Monthly={monthly_categories}\")\n",
    "print(f\"‚Ä¢ Statuses: Raw={raw_statuses}, Daily={daily_statuses}\")\n",
    "\n",
    "completeness_ok = (raw_categories == monthly_categories and raw_statuses == daily_statuses)\n",
    "print(f\"‚Ä¢ ‚úÖ Data completeness: {'PASSED' if completeness_ok else 'FAILED'}\")\n",
    "\n",
    "# Validation 5: Business Logic Validation\n",
    "print(f\"\\nüéØ BUSINESS LOGIC VALIDATION:\")\n",
    "business_validation = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        (SELECT COUNT(*) FROM {CONFIG['tables']['monthly_revenue']} WHERE total_revenue < 0) as negative_revenue,\n",
    "        (SELECT COUNT(*) FROM {CONFIG['tables']['monthly_revenue']} WHERE order_count <= 0) as invalid_order_counts,\n",
    "        (SELECT COUNT(*) FROM {CONFIG['tables']['daily_orders']} WHERE order_count <= 0) as invalid_daily_counts,\n",
    "        (SELECT COUNT(*) FROM {CONFIG['tables']['monthly_revenue']} WHERE avg_order_value <= 0) as invalid_avg_values\n",
    "\"\"\").fetchone()\n",
    "\n",
    "negative_revenue, invalid_monthly_counts, invalid_daily_counts, invalid_avg_values = business_validation\n",
    "\n",
    "print(f\"‚Ä¢ Negative revenue records: {negative_revenue}\")\n",
    "print(f\"‚Ä¢ Invalid monthly order counts: {invalid_monthly_counts}\")\n",
    "print(f\"‚Ä¢ Invalid daily order counts: {invalid_daily_counts}\")\n",
    "print(f\"‚Ä¢ Invalid average order values: {invalid_avg_values}\")\n",
    "\n",
    "business_logic_ok = all(x == 0 for x in business_validation)\n",
    "print(f\"‚Ä¢ ‚úÖ Business logic validation: {'PASSED' if business_logic_ok else 'FAILED'}\")\n",
    "\n",
    "# Overall Validation Summary\n",
    "all_validations_passed = all([\n",
    "    revenue_match,\n",
    "    orders_match,\n",
    "    date_consistency,\n",
    "    completeness_ok,\n",
    "    business_logic_ok\n",
    "])\n",
    "\n",
    "print(f\"\\nüéØ OVERALL VALIDATION RESULT:\")\n",
    "print(f\"{'='*50}\")\n",
    "if all_validations_passed:\n",
    "    print(\"üéâ ‚úÖ ALL VALIDATIONS PASSED!\")\n",
    "    print(\"   Analytical tables are accurate and ready for use.\")\n",
    "    validation_score = 100\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ‚ùå SOME VALIDATIONS FAILED!\")\n",
    "    print(\"   Please review the failed validations above.\")\n",
    "    validation_score = sum([revenue_match, orders_match, date_consistency, completeness_ok, business_logic_ok]) / 5 * 100\n",
    "\n",
    "print(f\"üìä Validation Score: {validation_score:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe9512",
   "metadata": {},
   "source": [
    "## üì§ Step 2.8: Export Results Summary\n",
    "\n",
    "Create summary report of Stage 2 analytical processing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58fe9715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Stage 2 Analytical Processing - Results Summary\n",
      "============================================================\n",
      "\n",
      "üìä PROCESSING STATISTICS:\n",
      "‚Ä¢ Total raw records: 128,975\n",
      "‚Ä¢ Successfully processed: 128,746\n",
      "‚Ä¢ Excluded (quality issues): 229\n",
      "‚Ä¢ Processing success rate: 99.82%\n",
      "\n",
      "üóÉÔ∏è ANALYTICAL TABLES CREATED:\n",
      "‚Ä¢ monthly_revenue_by_category: 31 records\n",
      "‚Ä¢ daily_orders_by_status: 456 records\n",
      "\n",
      "üíº KEY BUSINESS METRICS:\n",
      "‚Ä¢ Total Revenue: $78,592,678.30\n",
      "‚Ä¢ Total Orders: 118,837\n",
      "‚Ä¢ Product Categories: 9\n",
      "‚Ä¢ Months Covered: 4\n",
      "‚Ä¢ Average Order Value: $661.35\n",
      "‚Ä¢ States/Regions: 68\n",
      "\n",
      "üìà MONTHLY REVENUE ANALYSIS:\n",
      "‚Ä¢ Months processed: 31\n",
      "‚Ä¢ Monthly revenue range: $280.00 - $15,506,675.56\n",
      "‚Ä¢ Average monthly revenue: $2,535,247.69\n",
      "\n",
      "üìÖ DAILY ORDERS ANALYSIS:\n",
      "‚Ä¢ Days processed: 456\n",
      "‚Ä¢ Order status types: 12\n",
      "‚Ä¢ Daily orders range: 1 - 1368\n",
      "‚Ä¢ Average daily orders: 282\n",
      "\n",
      "‚úÖ STAGE 2 COMPLETION STATUS:\n",
      "============================================================\n",
      "üéØ Status: COMPLETED WITH WARNINGS\n",
      "üìä Validation Score: 60%\n",
      "‚è±Ô∏è Completion Time: 2025-11-15 00:34:50\n",
      "üìÅ Analytical Tables: 2 tables created and validated\n",
      "üöÄ Ready for Stage 3: Data Visualization & Dashboards\n",
      "\n",
      "============================================================\n",
      "‚ú® Stage 2 Analytical Processing Complete! ‚ú®\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Export Stage 2 Results Summary\n",
    "print(\"üì§ Stage 2 Analytical Processing - Results Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate comprehensive summary report\n",
    "summary_data = {}\n",
    "\n",
    "# 1. Processing Statistics\n",
    "summary_data['processing_stats'] = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_raw_records,\n",
    "        COUNT(CASE WHEN data_quality_flag IS NULL THEN 1 END) as processed_records,\n",
    "        COUNT(CASE WHEN data_quality_flag IS NOT NULL THEN 1 END) as excluded_records,\n",
    "        ROUND(COUNT(CASE WHEN data_quality_flag IS NULL THEN 1 END) * 100.0 / COUNT(*), 2) as processing_rate\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "# 2. Analytical Tables Created\n",
    "summary_data['tables_created'] = [\n",
    "    ('monthly_revenue_by_category', conn.execute(\"SELECT COUNT(*) FROM main_db.monthly_revenue_by_category\").fetchone()[0]),\n",
    "    ('daily_orders_by_status', conn.execute(\"SELECT COUNT(*) FROM main_db.daily_orders_by_status\").fetchone()[0])\n",
    "]\n",
    "\n",
    "# 3. Key Business Metrics\n",
    "summary_data['business_metrics'] = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        SUM(amount) as total_revenue,\n",
    "        COUNT(*) as total_orders,\n",
    "        COUNT(DISTINCT category) as categories,\n",
    "        COUNT(DISTINCT EXTRACT(MONTH FROM date_col)) as months_covered,\n",
    "        AVG(amount) as avg_order_value,\n",
    "        COUNT(DISTINCT ship_state) as states_covered\n",
    "    FROM {CONFIG['tables']['raw_data']}\n",
    "    WHERE amount > 0 AND data_quality_flag IS NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "# 4. Monthly Revenue Summary\n",
    "summary_data['monthly_summary'] = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as months_processed,\n",
    "        MIN(total_revenue) as min_monthly_revenue,\n",
    "        MAX(total_revenue) as max_monthly_revenue,\n",
    "        AVG(total_revenue) as avg_monthly_revenue\n",
    "    FROM {CONFIG['tables']['monthly_revenue']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "# 5. Daily Orders Summary  \n",
    "summary_data['daily_summary'] = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as days_processed,\n",
    "        COUNT(DISTINCT status) as status_types,\n",
    "        MIN(order_count) as min_daily_orders,\n",
    "        MAX(order_count) as max_daily_orders,\n",
    "        AVG(order_count) as avg_daily_orders\n",
    "    FROM {CONFIG['tables']['daily_orders']}\n",
    "\"\"\").fetchone()\n",
    "\n",
    "# Print formatted summary\n",
    "print(f\"\\nüìä PROCESSING STATISTICS:\")\n",
    "stats = summary_data['processing_stats']\n",
    "print(f\"‚Ä¢ Total raw records: {stats[0]:,}\")\n",
    "print(f\"‚Ä¢ Successfully processed: {stats[1]:,}\")\n",
    "print(f\"‚Ä¢ Excluded (quality issues): {stats[2]:,}\")\n",
    "print(f\"‚Ä¢ Processing success rate: {stats[3]}%\")\n",
    "\n",
    "print(f\"\\nüóÉÔ∏è ANALYTICAL TABLES CREATED:\")\n",
    "for table_name, record_count in summary_data['tables_created']:\n",
    "    print(f\"‚Ä¢ {table_name}: {record_count:,} records\")\n",
    "\n",
    "print(f\"\\nüíº KEY BUSINESS METRICS:\")\n",
    "metrics = summary_data['business_metrics']\n",
    "print(f\"‚Ä¢ Total Revenue: ${metrics[0]:,.2f}\")\n",
    "print(f\"‚Ä¢ Total Orders: {metrics[1]:,}\")\n",
    "print(f\"‚Ä¢ Product Categories: {metrics[2]}\")\n",
    "print(f\"‚Ä¢ Months Covered: {metrics[3]}\")\n",
    "print(f\"‚Ä¢ Average Order Value: ${metrics[4]:.2f}\")\n",
    "print(f\"‚Ä¢ States/Regions: {metrics[5]}\")\n",
    "\n",
    "print(f\"\\nüìà MONTHLY REVENUE ANALYSIS:\")\n",
    "monthly = summary_data['monthly_summary']\n",
    "print(f\"‚Ä¢ Months processed: {monthly[0]}\")\n",
    "print(f\"‚Ä¢ Monthly revenue range: ${monthly[1]:,.2f} - ${monthly[2]:,.2f}\")\n",
    "print(f\"‚Ä¢ Average monthly revenue: ${monthly[3]:,.2f}\")\n",
    "\n",
    "print(f\"\\nüìÖ DAILY ORDERS ANALYSIS:\")\n",
    "daily = summary_data['daily_summary']\n",
    "print(f\"‚Ä¢ Days processed: {daily[0]}\")\n",
    "print(f\"‚Ä¢ Order status types: {daily[1]}\")\n",
    "print(f\"‚Ä¢ Daily orders range: {daily[2]} - {daily[3]}\")\n",
    "print(f\"‚Ä¢ Average daily orders: {daily[4]:.0f}\")\n",
    "\n",
    "# Export summary to staging for use in other stages\n",
    "export_summary = {\n",
    "    'stage': 'Stage 2 - Analytical Processing',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'status': 'COMPLETED',\n",
    "    'validation_score': validation_score,\n",
    "    'tables_created': ['monthly_revenue_by_category', 'daily_orders_by_status'],\n",
    "    'records_processed': stats[1],\n",
    "    'total_revenue': float(metrics[0]),\n",
    "    'total_orders': metrics[1],\n",
    "    'processing_rate': float(stats[3])\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ STAGE 2 COMPLETION STATUS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üéØ Status: {'SUCCESSFUL' if validation_score == 100 else 'COMPLETED WITH WARNINGS'}\")\n",
    "print(f\"üìä Validation Score: {validation_score:.0f}%\")\n",
    "print(f\"‚è±Ô∏è Completion Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìÅ Analytical Tables: 2 tables created and validated\")\n",
    "print(f\"üöÄ Ready for Stage 3: Data Visualization & Dashboards\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® Stage 2 Analytical Processing Complete! ‚ú®\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
